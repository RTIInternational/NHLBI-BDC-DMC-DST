# Introduction
This guide will provide instruction and information on setting up the development environment for the BioData Catalyst (BDC) Data Management Core (DMC) Data Submission Tracker (DST). This will include installing prerequisites, setting up a development environment, building the container, deploying to BioData Catalyst, running tests/linting, and information about contributing to development.
> At this point all installation is managed system-wide. I think this is a poor way to manage a development environment. I would prefer that we use an environmental encapsulation of some sort, such as poetry or pyenv. We will try to move towards some encapsulation after we have an initial working environment.

---
# Contributing to the Project
To contribute to the project, follow the steps outlined in the [Setup the Development Environment](#setup-the-development-environment) section to create a local development environment. Once your environment is set up, you can make changes to the codebase and submit pull requests for review. If you encounter any issues during the setup process or while working on the project please submit an issue and describe the steps you are having trouble with.

---
# Setup the Development Environment
The steps necessary to set up the development are fairly  involved. First we will need to satisfy the [Prerequisites](#prerequisites), including [Dependencies](#dependencies), [Optional Dependencies](#optional-dependencies), and [Provision PostgreSQL VM on GCP](#provision-postgresql-vm-on-gcp). Please follow these instructions to properly set up and verify a functioning development environment.

## Prerequisites
In order to build and run the Data Submission tracker several dependencies will need to be installed and several requirements for the environment will need to be prepared. First we will describe the required dependencies, after these are installed we can set up the appropriate environment to build, run, and test the DST.

### Dependencies
The DST has a number of dependencies that are necessary both for building and deployment as well as for development. The primary development environment is currently Ubuntu 22.04 but other environments will be added as requested. Currently, development of the Data Submission Tracker requires these software tools available or installed on the development system.

 - Docker

 See [Install Prerequisites](#Install-Dependencies) section for how to install and set up each of these dependencies.

### Optional Dependencies
Because the Data Submission Tracker runs in a Docker container and all the relevant code is run within the container these additional dependencies are not strictly necessary for installation on the development system. However, for testing and troubleshooting we recommend also installing the following dependencies.

 - Python v3.10.6 or higher
 - Django v4.1.4 - higher version not currently recommended

I recommend using pyenv and venv to manage the python version and virtual environment. For detailed instructions on how I set up my Python development see [Python Development Environment](#python-development-environment).

Now the PostgreSQL database should be ready to receive connections from the Django app. We will migrate the Django model automatically when we build the tracker container. However, if you have installed Django locally you can migrate the Django model manually see `ansible/README.md` for instructions.

### Environment Variables
For development purposes a number of environment variables need to be set. In the `api` folder create a `.env` file with the following data.

``` .env
# Environment variables
# For local development, the api directory should have an .env file with the following:

# Set to True for local dev and False for prod
DEBUG=True

# Set to DEBUG for local dev and INFO for prod
DJANGO_LOG_LEVEL=DEBUG

# The Project ID for GCP
GOOGLE_CLOUD_PROJECT=

# The SECRET_KEY generated by Django
SECRET_KEY=

# The Postgres database name
POSTGRES_DB=tickets

# The username of the Postgres User
POSTGRES_USER=postgres

# A (secure) password for the Postgres User
POSTGRES_PASSWORD=

# The external IP for the Compute Engine instance with Postgres
POSTGRES_HOST=

# The port for the Postgres Database
POSTGRES_PORT=5432

# The client ID for Google OAuth2
GOOGLE_CLIENT_ID=

# The client secret for Google OAuth2
GOOGLE_CLIENT_SECRET=

```

You will need to update `GOOGLE_CLOUD_PROJECT`, `SECRET_KEY`, `POSTGRES_PASSWORD`, `POSTGRES_HOST`, `GOOGLE_CLIENT_ID`, and `GOOGLE_CLIENT_SECRET` with settings appropriate to your configuration from the steps in the [Prerequisites](#Prerequisites) section above. If you don't have a Django `SECRET_KEY` you can create one with the following command (Django local install required).

``` shell
python -c 'from django.core.management.utils import get_random_secret_key; print(get_random_secret_key())'
```

## Build Tracker Docker Container
With the PostgreSQL database set up and running and the environment variables set, the repository should be ready for development. To test the development environment, we will build the Docker container and access the application.

First, build the Docker container using `docker compose`.

``` shell
docker-compose-up.sh
```

To access the application navigate to `http://localhost:8000/` in your browser. You should see a login screen for the application with a button for `NIH login`. Login will not work at this time. In order to log in to the application we'll need to set the Django superuser. First, enter the local Docker container shell.

``` shell
docker exec -it bdc_dashboard_api_1 /bin/bash
```

Then create a Django superuser on the Docker container.

``` shell
python manage.py createsuperuser
```

Create a superuser with your desired credentials, generally your e-mail address and a password.

After creating the superuser you can authenticate on the Django app by navigating to `http://localhost:8000/admin`. Once authenticated, access the app at `http://localhost:8000/` to navigate the full application site. If all of these steps are successful you are now ready to begin development on the DMC Tracker app. 


---

# Install Dependencies

## Docker
Docker is an application containerization environment that allows software to be built in containers and deployed in different environments reducing dependencies and creating a more secure runtime environment by virtue of isolation from the host architecture. The Docker ecosystem provides both tools to create a container image and an engine to run those images on a target system. For basic build and development you will only need the container image creation tools. However, for proper testing and to allow access to the software in a development environment we will install both the image creation and engine portions.

### Uninstall unofficial packages or conflicting dependencies
Some distributions have unofficial Docker packages installed or dependencies that Docker will install separately. We need to uninstall these to prevent conflicts.
```shell
sudo apt-get remove docker.io docker-doc docker-compose podman-docker containerd runc
```
I had a stub installation to satisfy another packages spurious dependency. Here's how to check if a docker command still exists.
```shell
command -v docker
```
If the command still exists it is probably a stub. To check try running it. If there is no output, or a message that it isn't a real docker installation, check the file by opening it. If there is a stub file delete it. Replace '.local/bin/docker' with the path to your docker stub from the command above.
```shell
rm -rf .local/bin/docker
```

### System Requirements
Docker requires a 64-bit kernel (common on modern systems), 4 GB of RAM, configuring ID mapping in user namespaces enabled. The Docker Desktop also requires a systemd init, and a desktop environment. 

### Software Requirements
Docker requires KVM virtualization support and QEMU version 5.2 or newer, `latest` recommended.

## Install Docker
You can install the Docker packages from a package by downloading the package from the [Docker Linux Install](https://docs.docker.com/desktop/install/linux-install/) page. I prefer to manage my installation with apt. 

### Prepare for installation
Make sure everything is up-to-date and allow using a repository over HTTPS
```shell
sudo apt-get update
sudo apt-get install ca-certificates curl gnupg
```

### Add Docker GPG Key
We need the Docker official GPG public key to use their apt repository.
```shell
sudo install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
sudo chmod a+r /etc/apt/keyrings/docker.gpg
```

### Set up the Docker Apt Repository
This will set up the Docker Apt Repository allowing ongoing updates of Docker using the system software updater.
```shell
echo \
  "deb [arch="$(dpkg --print-architecture)" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  "$(. /etc/os-release && echo "$VERSION_CODENAME")" stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
```

### Update Apt to fetch Docker Repository
We need to update the Apt cache in order to install from the Docker repository.
```shell
sudo apt-get update
```
This should show a line accessing downloader.docker.com for the systems installed release.

### Install Docker and tools
Now we can install Docker Engine, containerd, and Docker Compose. This will install the latest version, which is currently version 24.0.2.
```shell
sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose docker-compose-plugin
```
If you need to install a different version see the [Docker Engine Installation](https://docs.docker.com/engine/install/ubuntu/#install-docker-engine)  

Now let's test the docker installation.
```shell
sudo docker run hello-world
```

### Fix Docker permissions
Docker requires root access to run. This is a security risk and we need to fix it. The recommended way to do this is to add your user to the docker group. This will allow your user to run docker commands without sudo.
```shell
sudo usermod -aG docker ${USER}
```
You will then need to log in again or run the command below to gain the group permissions.
```shell
newgrp docker
```

### Install Docker Desktop
Docker Desktop is a GUI for managing Docker containers and VMs.
```shell
sudo apt install gnome-terminal
sudo apt remove docker-desktop
rm -r $HOME/.docker/desktop
sudo rm /usr/local/bin/com.docker.cli
sudo apt purge docker-desktop
```
Download the latest version of Docker Desktop from the [Docker Desktop](https://www.docker.com/products/docker-desktop) page. The latest version as of this writing is 4.1.1.

```shell
sudo apt-get update
sudo apt-get install ./docker-desktop-<version>-<arch>.deb
```

---
# Python Development Environment
The DST is written in Python and uses the Django framework. This section will cover setting up a Python development environment for the DST. Because of the complexity of this project, I recommend setting up pyenv, venv, and poetry to manage the Python environment. This will also allow you to install the exact versions of Python and Python packages required for the DST.

## pyenv
pyenv is a Python version manager. It allows you to install and manage multiple versions of Python on the same system. It also allows you to install the exact version of Python required for a project. This allows you to use the same version of Python in development and as the DST will use in production.

First, we need to install the python build dependencies.
```shell
sudo apt update
```
```shell
sudo apt install build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev curl libncursesw5-dev xz-utils tk-dev libxml2-dev libxmlsec1-dev libffi-dev liblzma-dev
```

Now we can install pyenv. This will install pyenv to the `~/.pyenv` directory.
```bash
curl https://pyenv.run | bash
```

Now we need to add pyenv to the PATH. Add the following to the end of your `~/.bashrc` file.
```bash
export PYENV_ROOT="$HOME/.pyenv"
export PATH="$PYENV_ROOT/bin:$PATH"
eval "$(pyenv init --path)"
```

Now we can install the version of Python required for the DST.
```shell
pyenv install 3.11.1
```

To use pyenv local to your repository you can run the following command in the root of your repository, `cd /path/to/repository`.
```shell
pyenv local 3.11.1
```

## venv
venv is a Python module that allows you to create virtual environments for Python. This allows you to install Python packages for a specific project without affecting the system Python installation. This is useful for isolating the Python environment for the DST.

To create a virtual environment for the DST run the following command in the root of your repository.
```shell
python -m venv .venv
```

I create a file named `venv_name.txt` in the root of the venv directory. This file contains the name of the virtual environment. I use this in my .bashrc to read the name and track which virtual environment I have active in $PS1. This is optional but I find it useful. If you would like to know how to do this please reach out and I'll share my .bashrc.
```shell
echo "dst" > .venv/venv_name.txt
````

To activate the virtual environment run the following command in the root of your repository.
```shell
source .venv/bin/activate
```

To deactivate the virtual environment run the following command in the root of your repository.
```shell
deactivate
```

## Poetry
Poetry is a Python dependency manager. It allows you to manage Python dependencies for a project. Poetry will also create a virtual environment for the project and install the dependencies in that environment. This allows you to install the exact versions of dependencies required for the DST.

Install poetry with pip in the virtual environment then initialize with the following commands.
```shell
pip install poetry
poetry init
```
Set up the 

Reformat requirements.txt and install in Poetry virtual environment with the following command.
```shell
poetry add $(sed -E 's/;.*$//; s/\[.*\]//g' api/requirements.txt)
poetry add --extras "grpc" google-api-core
poetry add --extras "crypto" pyjwt
poetry install
```
